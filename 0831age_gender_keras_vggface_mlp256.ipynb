{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0831age_gender_keras_vggface_mlp256.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erichsiao1106/Aiottest/blob/master/0831age_gender_keras_vggface_mlp256.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Enr3u7SZ0rHX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "outputId": "83aa3ff1-0198-4731-d22e-4209642422a0"
      },
      "source": [
        "!pip install mtcnn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mtcnn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/43/abee91792797c609c1bf30f1112117f7a87a713ebaa6ec5201d5555a73ef/mtcnn-0.1.0-py3-none-any.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from mtcnn) (2.4.3)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from mtcnn) (4.1.2.30)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (1.18.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras>=2.0.0->mtcnn) (1.15.0)\n",
            "Installing collected packages: mtcnn\n",
            "Successfully installed mtcnn-0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HiBB7Hk1Cr-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy.io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "#import tensorflow as tf\n",
        "#from tensorflow import keras\n",
        "import keras\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Activation\n",
        "from keras.layers import Conv2D, AveragePooling2D, BatchNormalization\n",
        "from keras.models import Model, Sequential\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "from keras import metrics\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from keras.models import load_model\n",
        "import cv2\n",
        "from glob import glob\n",
        "import os\n",
        "from mtcnn import MTCNN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hfiio5_KHufK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "8d2d026e-0932-45ee-afef-8b7fa545f65d"
      },
      "source": [
        "df = pd.read_csv('drive/My Drive/AIoT_Project/Datasets/資料集_IMDB-Wiki/wiki_crop/wiki_mat.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-39f46df82cc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive/My Drive/AIoT_Project/Datasets/資料集_IMDB-Wiki/wiki_crop/wiki_mat.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File drive/My Drive/AIoT_Project/Datasets/資料集_IMDB-Wiki/wiki_crop/wiki_mat.csv does not exist: 'drive/My Drive/AIoT_Project/Datasets/資料集_IMDB-Wiki/wiki_crop/wiki_mat.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vj29J-vpoyz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "c461953c-fb28-4746-88b7-64b588bc8872"
      },
      "source": [
        "#some guys seem to be greater than 100. some of these are paintings. remove these old guys\n",
        "df = df[df['age'] <= 100]\n",
        " \n",
        "#some guys seem to be unborn in the data set\n",
        "df = df[df['age'] > 0]\n",
        "df['age'] = df['age']//10\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>full_path</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17/10000217_1981-05-05_2009.jpg</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12/100012_1948-07-03_2008.jpg</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16/10002116_1971-05-31_2012.jpg</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>02/10002702_1960-11-09_2012.jpg</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>41/10003541_1937-09-27_1971.jpg</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22150</th>\n",
              "      <td>38/9996938_1937-02-15_1968.jpg</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22151</th>\n",
              "      <td>46/9996946_1943-11-01_1968.jpg</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22152</th>\n",
              "      <td>49/9996949_1937-04-17_1963.jpg</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22153</th>\n",
              "      <td>09/9998109_1972-12-27_2013.jpg</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22154</th>\n",
              "      <td>80/999980_1954-06-11_2008.jpg</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>22138 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                             full_path  gender  age\n",
              "0      17/10000217_1981-05-05_2009.jpg     1.0    2\n",
              "1        12/100012_1948-07-03_2008.jpg     1.0    6\n",
              "2      16/10002116_1971-05-31_2012.jpg     0.0    4\n",
              "3      02/10002702_1960-11-09_2012.jpg     0.0    5\n",
              "4      41/10003541_1937-09-27_1971.jpg     1.0    3\n",
              "...                                ...     ...  ...\n",
              "22150   38/9996938_1937-02-15_1968.jpg     1.0    3\n",
              "22151   46/9996946_1943-11-01_1968.jpg     1.0    2\n",
              "22152   49/9996949_1937-04-17_1963.jpg     1.0    2\n",
              "22153   09/9998109_1972-12-27_2013.jpg     1.0    4\n",
              "22154    80/999980_1954-06-11_2008.jpg     0.0    5\n",
              "\n",
              "[22138 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UozAFd9tMHp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynsfUWLDp4r7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "b1b5b1ec-ff9a-4270-8e99-23728f7d6d73"
      },
      "source": [
        "histogram_age = df['age'].hist(bins=df['age'].nunique())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpW1u6dgrNOe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fc26151c-9878-4c3b-fcca-7e413befa45d"
      },
      "source": [
        "# 處理答案 把它轉成one-hot\n",
        "y_train_category = to_categorical(df['age'])\n",
        "\n",
        "# 切分訓練data\n",
        "x_train, x_test, y_train, y_test = train_test_split(np.array(df['full_path']), np.array(y_train_category), test_size=0.2)\n",
        "print(x_train[0], x_test[0], y_train[0], y_train[0].argmax(axis=-1), y_test[0].argmax(axis=-1))\n",
        "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "89/5377589_1956-05-19_2012.jpg 72/22919372_1954-08-16_2009.jpg [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 5 5\n",
            "(17710,) (4428,) (17710, 11) (4428, 11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZJoKwSbtpb8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "folder_path = 'drive/My Drive/Tibame_AIoT_Project/Datasets/資料集_IMDB-Wiki'\n",
        "detector = MTCNN()\n",
        "#feature_extractor = load_model(os.path.join(folder_path, 'facenet.h5'))\n",
        "#feature_extractor = load_model(os.path.join(folder_path, 'facenet_keras.h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DypYAJ7cJlrC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "4083ba11-ab1d-48af-b3ec-8c6f522b2f30"
      },
      "source": [
        "# VGGFace: https://github.com/rcmalli/keras-vggface\n",
        "!pip install keras_vggface\n",
        "!pip install keras_applications\n",
        "\n",
        "from keras_vggface.vggface import VGGFace\n",
        "from keras_vggface.utils import preprocess_input\n",
        "feature_extractor = VGGFace(model='resnet50', include_top=False, \n",
        "            input_shape=(224, 224, 3), pooling='avg')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras_vggface\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/7d/5f0319ebdc09ac1a2272364fa9583f5067b6f8aff93fbbf8835d81cbaad7/keras_vggface-0.6-py3-none-any.whl\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (3.13)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (7.0.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (2.10.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (2.4.3)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (1.18.5)\n",
            "Installing collected packages: keras-vggface\n",
            "Successfully installed keras-vggface-0.6\n",
            "Collecting keras_applications\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 1.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras_applications) (1.18.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras_applications) (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras_applications) (1.15.0)\n",
            "Installing collected packages: keras-applications\n",
            "Successfully installed keras-applications-1.0.8\n",
            "Downloading data from https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_notop_resnet50.h5\n",
            "94699520/94694792 [==============================] - 7s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOgsPn1i3E21",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "02ae289b-e170-4a98-b22d-fd83148f697e"
      },
      "source": [
        "feature_extractor.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vggface_resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1/7x7_s2 (Conv2D)           (None, 112, 112, 64) 9408        input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1/7x7_s2/bn (BatchNormaliza (None, 112, 112, 64) 256         conv1/7x7_s2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 112, 112, 64) 0           conv1/7x7_s2/bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 55, 55, 64)   0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_reduce (Conv2D)     (None, 55, 55, 64)   4096        max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_1_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 55, 55, 64)   0           conv2_1_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_1_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 55, 55, 64)   0           conv2_1_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_proj (Conv2D)       (None, 55, 55, 256)  16384       max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_1_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_proj/bn (BatchNorma (None, 55, 55, 256)  1024        conv2_1_1x1_proj[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 55, 55, 256)  0           conv2_1_1x1_increase/bn[0][0]    \n",
            "                                                                 conv2_1_1x1_proj/bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 55, 55, 256)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_reduce (Conv2D)     (None, 55, 55, 64)   16384       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_2_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 55, 55, 64)   0           conv2_2_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_2_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 55, 55, 64)   0           conv2_2_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_2_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 55, 55, 256)  0           conv2_2_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 55, 55, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_reduce (Conv2D)     (None, 55, 55, 64)   16384       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_3_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 55, 55, 64)   0           conv2_3_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_3_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 55, 55, 64)   0           conv2_3_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_3_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 55, 55, 256)  0           conv2_3_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 55, 55, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_reduce (Conv2D)     (None, 28, 28, 128)  32768       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_1_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 28, 28, 128)  0           conv3_1_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_1_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 28, 28, 128)  0           conv3_1_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_proj (Conv2D)       (None, 28, 28, 512)  131072      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_1_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_proj/bn (BatchNorma (None, 28, 28, 512)  2048        conv3_1_1x1_proj[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 28, 28, 512)  0           conv3_1_1x1_increase/bn[0][0]    \n",
            "                                                                 conv3_1_1x1_proj/bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 28, 28, 512)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_2_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 28, 28, 128)  0           conv3_2_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_2_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 28, 28, 128)  0           conv3_2_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_2_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 28, 28, 512)  0           conv3_2_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_3_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 28, 28, 128)  0           conv3_3_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_3_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 28, 28, 128)  0           conv3_3_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_3_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 28, 28, 512)  0           conv3_3_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_4_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 28, 28, 128)  0           conv3_4_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_4_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 28, 28, 128)  0           conv3_4_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_4_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 28, 28, 512)  0           conv3_4_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_reduce (Conv2D)     (None, 14, 14, 256)  131072      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_1_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 14, 14, 256)  0           conv4_1_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_1_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 14, 14, 256)  0           conv4_1_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_proj (Conv2D)       (None, 14, 14, 1024) 524288      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_1_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_proj/bn (BatchNorma (None, 14, 14, 1024) 4096        conv4_1_1x1_proj[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 14, 14, 1024) 0           conv4_1_1x1_increase/bn[0][0]    \n",
            "                                                                 conv4_1_1x1_proj/bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 14, 14, 1024) 0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_2_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 14, 14, 256)  0           conv4_2_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_2_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 14, 14, 256)  0           conv4_2_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_2_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 14, 14, 1024) 0           conv4_2_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_3_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 14, 14, 256)  0           conv4_3_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_3_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 14, 14, 256)  0           conv4_3_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_3_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 14, 14, 1024) 0           conv4_3_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_4_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 14, 14, 256)  0           conv4_4_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_4_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 14, 14, 256)  0           conv4_4_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_4_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 14, 14, 1024) 0           conv4_4_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_5_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 14, 14, 256)  0           conv4_5_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_5_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 14, 14, 256)  0           conv4_5_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_5_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 14, 14, 1024) 0           conv4_5_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_6_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 14, 14, 256)  0           conv4_6_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_6_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 14, 14, 256)  0           conv4_6_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_6_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 14, 14, 1024) 0           conv4_6_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_reduce (Conv2D)     (None, 7, 7, 512)    524288      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_1_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 512)    0           conv5_1_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_1_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 512)    0           conv5_1_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_proj (Conv2D)       (None, 7, 7, 2048)   2097152     activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_1_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_proj/bn (BatchNorma (None, 7, 7, 2048)   8192        conv5_1_1x1_proj[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 7, 7, 2048)   0           conv5_1_1x1_increase/bn[0][0]    \n",
            "                                                                 conv5_1_1x1_proj/bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 2048)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_2_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 512)    0           conv5_2_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_2_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 512)    0           conv5_2_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_2_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 7, 7, 2048)   0           conv5_2_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_3_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 512)    0           conv5_3_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_3_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 512)    0           conv5_3_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_3_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 7, 7, 2048)   0           conv5_3_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 2048)         0           avg_pool[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 23,561,152\n",
            "Trainable params: 23,508,032\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iJ6QxgZ_8iI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "10e157c9-7e71-41cf-c692-d6b919ab6ce6"
      },
      "source": [
        "# 固定pre-train model的參數\n",
        "for lyr in feature_extractor.layers:\n",
        "    lyr.trainable = False\n",
        "\n",
        "# BN\n",
        "x = BatchNormalization()(feature_extractor.output)    \n",
        "    \n",
        "# MLP    \n",
        "# x = Flatten()(x)\n",
        "\n",
        "#x = Dense(units=2048, activation='relu')(x)\n",
        "x = Dense(units=256, activation='relu')(x)\n",
        "x = Dense(units=11, activation='softmax')(x)\n",
        "age_model = Model(inputs=feature_extractor.input, outputs=x)   \n",
        "age_model.summary() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_7\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1/7x7_s2 (Conv2D)           (None, 112, 112, 64) 9408        input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1/7x7_s2/bn (BatchNormaliza (None, 112, 112, 64) 256         conv1/7x7_s2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 112, 112, 64) 0           conv1/7x7_s2/bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 55, 55, 64)   0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_reduce (Conv2D)     (None, 55, 55, 64)   4096        max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_1_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 55, 55, 64)   0           conv2_1_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_1_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 55, 55, 64)   0           conv2_1_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_proj (Conv2D)       (None, 55, 55, 256)  16384       max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_1_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_proj/bn (BatchNorma (None, 55, 55, 256)  1024        conv2_1_1x1_proj[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 55, 55, 256)  0           conv2_1_1x1_increase/bn[0][0]    \n",
            "                                                                 conv2_1_1x1_proj/bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 55, 55, 256)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_reduce (Conv2D)     (None, 55, 55, 64)   16384       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_2_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 55, 55, 64)   0           conv2_2_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_2_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 55, 55, 64)   0           conv2_2_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_2_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 55, 55, 256)  0           conv2_2_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 55, 55, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_reduce (Conv2D)     (None, 55, 55, 64)   16384       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_3_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 55, 55, 64)   0           conv2_3_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_3_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 55, 55, 64)   0           conv2_3_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_3_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 55, 55, 256)  0           conv2_3_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 55, 55, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_reduce (Conv2D)     (None, 28, 28, 128)  32768       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_1_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 28, 28, 128)  0           conv3_1_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_1_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 28, 28, 128)  0           conv3_1_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_proj (Conv2D)       (None, 28, 28, 512)  131072      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_1_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_proj/bn (BatchNorma (None, 28, 28, 512)  2048        conv3_1_1x1_proj[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 28, 28, 512)  0           conv3_1_1x1_increase/bn[0][0]    \n",
            "                                                                 conv3_1_1x1_proj/bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 28, 28, 512)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_2_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 28, 28, 128)  0           conv3_2_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_2_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 28, 28, 128)  0           conv3_2_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_2_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 28, 28, 512)  0           conv3_2_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_3_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 28, 28, 128)  0           conv3_3_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_3_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 28, 28, 128)  0           conv3_3_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_3_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 28, 28, 512)  0           conv3_3_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_4_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 28, 28, 128)  0           conv3_4_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_4_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 28, 28, 128)  0           conv3_4_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_4_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 28, 28, 512)  0           conv3_4_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_reduce (Conv2D)     (None, 14, 14, 256)  131072      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_1_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 14, 14, 256)  0           conv4_1_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_1_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 14, 14, 256)  0           conv4_1_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_proj (Conv2D)       (None, 14, 14, 1024) 524288      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_1_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_proj/bn (BatchNorma (None, 14, 14, 1024) 4096        conv4_1_1x1_proj[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 14, 14, 1024) 0           conv4_1_1x1_increase/bn[0][0]    \n",
            "                                                                 conv4_1_1x1_proj/bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 14, 14, 1024) 0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_2_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 14, 14, 256)  0           conv4_2_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_2_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 14, 14, 256)  0           conv4_2_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_2_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 14, 14, 1024) 0           conv4_2_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_3_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 14, 14, 256)  0           conv4_3_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_3_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 14, 14, 256)  0           conv4_3_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_3_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 14, 14, 1024) 0           conv4_3_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_4_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 14, 14, 256)  0           conv4_4_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_4_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 14, 14, 256)  0           conv4_4_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_4_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 14, 14, 1024) 0           conv4_4_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_5_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 14, 14, 256)  0           conv4_5_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_5_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 14, 14, 256)  0           conv4_5_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_5_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 14, 14, 1024) 0           conv4_5_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_6_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 14, 14, 256)  0           conv4_6_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_6_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 14, 14, 256)  0           conv4_6_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_6_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 14, 14, 1024) 0           conv4_6_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_reduce (Conv2D)     (None, 7, 7, 512)    524288      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_1_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 512)    0           conv5_1_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_1_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 512)    0           conv5_1_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_proj (Conv2D)       (None, 7, 7, 2048)   2097152     activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_1_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_proj/bn (BatchNorma (None, 7, 7, 2048)   8192        conv5_1_1x1_proj[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 7, 7, 2048)   0           conv5_1_1x1_increase/bn[0][0]    \n",
            "                                                                 conv5_1_1x1_proj/bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 2048)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_2_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 512)    0           conv5_2_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_2_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 512)    0           conv5_2_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_2_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 7, 7, 2048)   0           conv5_2_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_3_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 512)    0           conv5_3_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_3_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 512)    0           conv5_3_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_3_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 7, 7, 2048)   0           conv5_3_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 2048)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 2048)         8192        global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 256)          524544      batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 11)           2827        dense_7[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 24,096,715\n",
            "Trainable params: 531,467\n",
            "Non-trainable params: 23,565,248\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bs6tioz-AvmI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "age_model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model_folder_path = 'drive/My Drive/Tibame_AIoT_Project/face'\n",
        "age_model.load_weights(os.path.join(model_folder_path,'keras_vggface_weights_age_256.h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-Mn0wTy5Bze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 資料預處理 for facenet?\n",
        "# Standardization\n",
        "def preprocess(imgs): \n",
        "    for i in range(imgs.shape[0]):\n",
        "        # standardization\n",
        "        img = imgs[i]\n",
        "        mean, std = img.mean(), img.std()\n",
        "        img = (img - mean) / std\n",
        "        imgs[i] = img\n",
        "    return imgs\n",
        "# Normalization\n",
        "def normalize(img):\n",
        "    return img / 255.\n",
        "\n",
        "# -1 <= x <= 1\n",
        "def preprocess_1(imgs):\n",
        "    x = np.array(imgs, dtype = float)\n",
        "    x /= 127.5\n",
        "    x -= 1.\n",
        "    return x    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQW4TywAzi7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# n = np.array([[255,127,1],\n",
        "#         [128,200,255]])\n",
        "# print(preprocess_1(n))\n",
        "# print(n)\n",
        "# print(preprocess(n))\n",
        "# print(n)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evAgdxQ20ICI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# detect face\n",
        "def detect_faces(img):\n",
        "    face_imgs = []\n",
        "    results = detector.detect_faces(img)\n",
        "    # extract the bounding box from the first face\n",
        "    # print('# of faces: ', len(results))\n",
        "    for i in range(len(results)):\n",
        "        x1, y1, width, height = results[i]['box']\n",
        "        x2, y2 = x1 + width, y1 + height\n",
        "        patch = img[y1:y2, x1:x2] # crop face\n",
        "        face_imgs.append(patch)\n",
        "    return face_imgs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIl32It8IiIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_folder_path = 'drive/My Drive/Tibame_AIoT_Project/Datasets/資料集_IMDB-Wiki/wiki_crop'\n",
        "def get_data(x, y, batch=20, IMG_SIZE=160):\n",
        "    # 要注意 numpy 中的 randint 的上限是不包含的 和一般的randint不同\n",
        "    # numpy array 的索引可以是個 list, 即可同時取出不只一個元素\n",
        "    idx = np.random.randint(0, len(x), batch)\n",
        "    x_idx, y_idx = x[idx], y[idx]\n",
        "    x_ori, x_norm, y_ori = [], [], y_idx\n",
        "    for i,p in enumerate(x_idx):\n",
        "        #print(p[0])\n",
        "        #print(y_idx[i].argmax(axis=-1))\n",
        "        # 讀取圖片並使用借來的模型的預處理方式來作預處理\n",
        "        # img = np.array(load_img(os.path.join(img_folder_path,p[0]), target_size=(224, 224)))\n",
        "        # 讀取圖片並切下臉的部分\n",
        "        img = np.array(cv2.imread(os.path.join(img_folder_path,p))[:,:,::-1])\n",
        "        # plt.imshow(img)\n",
        "        # plt.show()\n",
        "        faces = detect_faces(img)\n",
        "        if len(faces) == 0:\n",
        "            print('No face')\n",
        "            continue   \n",
        "        img = cv2.resize(faces[0], (IMG_SIZE, IMG_SIZE))\n",
        "        # plt.imshow(faces[0])\n",
        "        # plt.show()\n",
        "\n",
        "        # 使用借來的模型的預處理方式來作預處理\n",
        "        img_pre = preprocess_input(np.array(img,dtype=float))\n",
        "        #img_pre = preprocess_1(img)\n",
        "        #img_pre = normalize(img)\n",
        "        \n",
        "        # 把原圖留下來\n",
        "        x_ori.append(img)\n",
        "        x_norm.append(img_pre)\n",
        "    return np.array(x_ori), np.array(x_norm), np.array(y_ori)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPHLvOL8JGg-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "122c8fab-ac9a-4fac-b8d6-d0086bc16f74"
      },
      "source": [
        "# 批次訓練\n",
        "i = 0\n",
        "while i < 100:\n",
        "    print(\"[times]:\", i)\n",
        "    x_ori_batch, x_batch, y_batch = get_data(x_train, y_train, IMG_SIZE=224)\n",
        "    print(\"preprocess:\", x_ori_batch[0,0,0,:], \"==>\", x_batch[0,0,0,:] )\n",
        "    print(x_batch.shape, y_batch.shape)\n",
        "    if x_batch.shape[0] != y_batch.shape[0]:\n",
        "        continue\n",
        "    result = age_model.train_on_batch(x_batch, y_batch, reset_metrics=False)\n",
        "    print(\"[Train]:\", result)\n",
        "    \n",
        "    # _, x_batch, y_batch = get_data(x_test, y_test, IMG_SIZE=224)\n",
        "    # print(x_batch.shape, y_batch.shape)\n",
        "    # if x_batch.shape[0] != y_batch.shape[0]:\n",
        "    #     continue    \n",
        "    # result = age_model.test_on_batch(x_batch, y_batch)\n",
        "    # print(\"[Test]:\", result)\n",
        "\n",
        "    i += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[times]: 0\n",
            "preprocess: [93 70 64] ==> [-29.594  -34.7624 -36.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [2.0194480419158936, 0.4000000059604645]\n",
            "[times]: 1\n",
            "preprocess: [233 190 174] ==> [ 80.406   85.2376 103.8137]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.8894611597061157, 0.42500001192092896]\n",
            "[times]: 2\n",
            "preprocess: [125 114 108] ==> [14.406   9.2376 -4.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [2.054832696914673, 0.38333332538604736]\n",
            "[times]: 3\n",
            "preprocess: [154 150 121] ==> [27.406  45.2376 24.8137]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [2.115879535675049, 0.36250001192092896]\n",
            "[times]: 4\n",
            "preprocess: [47 42 38] ==> [-55.594  -62.7624 -82.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [2.1471681594848633, 0.36000001430511475]\n",
            "[times]: 5\n",
            "preprocess: [151 131 122] ==> [28.406  26.2376 21.8137]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [2.139561891555786, 0.38333332538604736]\n",
            "[times]: 6\n",
            "preprocess: [247 246 241] ==> [147.406  141.2376 117.8137]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [2.094536542892456, 0.4000000059604645]\n",
            "[times]: 7\n",
            "preprocess: [217 221 215] ==> [121.406  116.2376  87.8137]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [2.049741268157959, 0.40625]\n",
            "[times]: 8\n",
            "preprocess: [82 81 79] ==> [-14.594  -23.7624 -47.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.9927160739898682, 0.41111111640930176]\n",
            "[times]: 9\n",
            "preprocess: [246 250 251] ==> [157.406  145.2376 116.8137]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.9934879541397095, 0.4099999964237213]\n",
            "[times]: 10\n",
            "preprocess: [236 254 254] ==> [160.406  149.2376 106.8137]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [2.002828359603882, 0.40909090638160706]\n",
            "[times]: 11\n",
            "preprocess: [201 198 227] ==> [133.406   93.2376  71.8137]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [2.010432481765747, 0.40833333134651184]\n",
            "[times]: 12\n",
            "preprocess: [35 22  3] ==> [-90.594  -82.7624 -94.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [2.006434917449951, 0.4038461446762085]\n",
            "[times]: 13\n",
            "preprocess: [170 168 147] ==> [53.406  63.2376 40.8137]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.9872925281524658, 0.4107142984867096]\n",
            "[times]: 14\n",
            "preprocess: [122 185 202] ==> [108.406   80.2376  -7.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [2.0381364822387695, 0.4033333361148834]\n",
            "[times]: 15\n",
            "preprocess: [55 55 55] ==> [-38.594  -49.7624 -74.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [2.0530459880828857, 0.40937501192092896]\n",
            "[times]: 16\n",
            "No face\n",
            "preprocess: [29 23 27] ==> [ -66.594   -81.7624 -100.1863]\n",
            "(19, 224, 224, 3) (20, 11)\n",
            "[times]: 16\n",
            "preprocess: [149 170 139] ==> [45.406  65.2376 19.8137]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [2.05090594291687, 0.4176470637321472]\n",
            "[times]: 17\n",
            "preprocess: [26 26 16] ==> [ -77.594   -78.7624 -103.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [2.0710208415985107, 0.42222222685813904]\n",
            "[times]: 18\n",
            "preprocess: [121  93  72] ==> [-21.594  -11.7624  -8.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [2.057223081588745, 0.4236842095851898]\n",
            "[times]: 19\n",
            "preprocess: [ 65 113 189] ==> [ 95.406    8.2376 -64.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [2.073108196258545, 0.42250001430511475]\n",
            "[times]: 20\n",
            "preprocess: [239 241 240] ==> [146.406  136.2376 109.8137]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [2.087949514389038, 0.4166666567325592]\n",
            "[times]: 21\n",
            "preprocess: [63 40 26] ==> [-67.594  -64.7624 -66.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [2.076014757156372, 0.415909081697464]\n",
            "[times]: 22\n",
            "preprocess: [19  8  6] ==> [ -87.594   -96.7624 -110.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [2.066701889038086, 0.41956523060798645]\n",
            "[times]: 23\n",
            "preprocess: [171 137 112] ==> [18.406  32.2376 41.8137]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [2.0531060695648193, 0.4229166805744171]\n",
            "[times]: 24\n",
            "preprocess: [88 68 61] ==> [-32.594  -36.7624 -41.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [2.0397958755493164, 0.41999998688697815]\n",
            "[times]: 25\n",
            "preprocess: [169 171 170] ==> [76.406  66.2376 39.8137]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [2.0469024181365967, 0.41730770468711853]\n",
            "[times]: 26\n",
            "No face\n",
            "preprocess: [156 143  99] ==> [ 5.406  38.2376 26.8137]\n",
            "(19, 224, 224, 3) (20, 11)\n",
            "[times]: 26\n",
            "preprocess: [165 142 100] ==> [ 6.406  37.2376 35.8137]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [2.0601184368133545, 0.41296297311782837]\n",
            "[times]: 27\n",
            "preprocess: [43 43 43] ==> [-50.594  -61.7624 -86.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [2.051626682281494, 0.4124999940395355]\n",
            "[times]: 28\n",
            "preprocess: [128 110 108] ==> [14.406   5.2376 -1.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [2.042987108230591, 0.41551724076271057]\n",
            "[times]: 29\n",
            "preprocess: [249 253 255] ==> [161.406  148.2376 119.8137]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [2.0514159202575684, 0.41499999165534973]\n",
            "[times]: 30\n",
            "preprocess: [77 49 28] ==> [-65.594  -55.7624 -52.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [2.04412841796875, 0.41774192452430725]\n",
            "[times]: 31\n",
            "preprocess: [57 46 42] ==> [-51.594  -58.7624 -72.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [2.0541491508483887, 0.4203124940395355]\n",
            "[times]: 32\n",
            "preprocess: [146 134  92] ==> [-1.594  29.2376 16.8137]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [2.0480823516845703, 0.42575758695602417]\n",
            "[times]: 33\n",
            "preprocess: [73 53 52] ==> [-41.594  -51.7624 -56.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [2.0623133182525635, 0.42352941632270813]\n",
            "[times]: 34\n",
            "preprocess: [23 22 18] ==> [ -75.594   -82.7624 -106.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [2.0655157566070557, 0.4214285612106323]\n",
            "[times]: 35\n",
            "preprocess: [84 69 62] ==> [-31.594  -35.7624 -45.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [2.0497467517852783, 0.42500001192092896]\n",
            "[times]: 36\n",
            "preprocess: [54 27  9] ==> [-84.594  -77.7624 -75.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [2.030614137649536, 0.4283783733844757]\n",
            "[times]: 37\n",
            "preprocess: [27 32 26] ==> [ -67.594   -72.7624 -102.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [2.0552923679351807, 0.42105263471603394]\n",
            "[times]: 38\n",
            "preprocess: [21 17 15] ==> [ -78.594   -87.7624 -108.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [2.039076328277588, 0.42692306637763977]\n",
            "[times]: 39\n",
            "preprocess: [69 69 69] ==> [-24.594  -35.7624 -60.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [2.0187201499938965, 0.4337500035762787]\n",
            "[times]: 40\n",
            "preprocess: [142 106  92] ==> [-1.594   1.2376 12.8137]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [2.0080294609069824, 0.43536585569381714]\n",
            "[times]: 41\n",
            "preprocess: [141 150 179] ==> [85.406  45.2376 11.8137]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.9869565963745117, 0.4404761791229248]\n",
            "[times]: 42\n",
            "preprocess: [106  88  76] ==> [-17.594  -16.7624 -23.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.9714133739471436, 0.4441860318183899]\n",
            "[times]: 43\n",
            "preprocess: [76 66 57] ==> [-36.594  -38.7624 -53.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.9777185916900635, 0.44090908765792847]\n",
            "[times]: 44\n",
            "preprocess: [190 164 139] ==> [45.406  59.2376 60.8137]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.997359037399292, 0.4377777874469757]\n",
            "[times]: 45\n",
            "preprocess: [163 154 171] ==> [77.406  49.2376 33.8137]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.989696979522705, 0.43586957454681396]\n",
            "[times]: 46\n",
            "preprocess: [26 26 28] ==> [ -65.594   -78.7624 -103.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [2.004552125930786, 0.4340425431728363]\n",
            "[times]: 47\n",
            "preprocess: [216 223 252] ==> [158.406  118.2376  86.8137]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.9897767305374146, 0.4364583194255829]\n",
            "[times]: 48\n",
            "preprocess: [123 132 101] ==> [ 7.406  27.2376 -6.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.990968108177185, 0.4357142746448517]\n",
            "[times]: 49\n",
            "preprocess: [232 232 232] ==> [138.406  127.2376 102.8137]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.9867881536483765, 0.4359999895095825]\n",
            "[times]: 50\n",
            "preprocess: [179 173 149] ==> [55.406  68.2376 49.8137]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.9831912517547607, 0.4362744987010956]\n",
            "[times]: 51\n",
            "preprocess: [50 11 74] ==> [-19.594  -93.7624 -79.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.9738645553588867, 0.4403846263885498]\n",
            "[times]: 52\n",
            "preprocess: [188 188 188] ==> [94.406  83.2376 58.8137]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.9643142223358154, 0.4424528181552887]\n",
            "[times]: 53\n",
            "preprocess: [41 41 39] ==> [-54.594  -63.7624 -88.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.9570244550704956, 0.4453703761100769]\n",
            "[times]: 54\n",
            "preprocess: [14 16 16] ==> [ -77.594   -88.7624 -115.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.9517958164215088, 0.446363627910614]\n",
            "[times]: 55\n",
            "preprocess: [45 38 32] ==> [-61.594  -66.7624 -84.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.9278645515441895, 0.4526785612106323]\n",
            "[times]: 56\n",
            "preprocess: [70 70 72] ==> [-21.594  -34.7624 -59.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.9234861135482788, 0.4526315927505493]\n",
            "[times]: 57\n",
            "preprocess: [112 128 127] ==> [ 33.406   23.2376 -17.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.9332973957061768, 0.45258620381355286]\n",
            "[times]: 58\n",
            "preprocess: [28 17 13] ==> [ -80.594   -87.7624 -101.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.934359073638916, 0.44999998807907104]\n",
            "[times]: 59\n",
            "preprocess: [112  90  92] ==> [ -1.594  -14.7624 -17.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.9379746913909912, 0.44749999046325684]\n",
            "[times]: 60\n",
            "preprocess: [79 80 75] ==> [-18.594  -24.7624 -50.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.9389303922653198, 0.4475409984588623]\n",
            "[times]: 61\n",
            "preprocess: [60 49 45] ==> [-48.594  -55.7624 -69.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.9338006973266602, 0.448387086391449]\n",
            "[times]: 62\n",
            "preprocess: [201 202 206] ==> [112.406   97.2376  71.8137]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.9361684322357178, 0.4476190507411957]\n",
            "[times]: 63\n",
            "preprocess: [105 105 105] ==> [ 11.406    0.2376 -24.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.9272581338882446, 0.44999998807907104]\n",
            "[times]: 64\n",
            "preprocess: [0 0 0] ==> [ -93.594  -104.7624 -129.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.9144365787506104, 0.45230770111083984]\n",
            "[times]: 65\n",
            "preprocess: [65 57 54] ==> [-39.594  -47.7624 -64.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.9177873134613037, 0.44999998807907104]\n",
            "[times]: 66\n",
            "preprocess: [55 70 89] ==> [ -4.594  -34.7624 -74.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.920964002609253, 0.44925373792648315]\n",
            "[times]: 67\n",
            "preprocess: [131  83  79] ==> [-14.594  -21.7624   1.8137]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.9278616905212402, 0.447794109582901]\n",
            "[times]: 68\n",
            "preprocess: [ 93 104 149] ==> [ 55.406   -0.7624 -36.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.9205323457717896, 0.44999998807907104]\n",
            "[times]: 69\n",
            "preprocess: [18 18 16] ==> [ -77.594   -86.7624 -111.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.9077115058898926, 0.4521428644657135]\n",
            "[times]: 70\n",
            "preprocess: [161 163 162] ==> [68.406  58.2376 31.8137]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.9063538312911987, 0.45211267471313477]\n",
            "[times]: 71\n",
            "preprocess: [10 10 10] ==> [ -83.594   -94.7624 -119.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.9087661504745483, 0.4513888955116272]\n",
            "[times]: 72\n",
            "preprocess: [88 74 48] ==> [-45.594  -30.7624 -41.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.9028522968292236, 0.4527397155761719]\n",
            "[times]: 73\n",
            "preprocess: [110 169 203] ==> [109.406   64.2376 -19.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.8988324403762817, 0.4533783793449402]\n",
            "[times]: 74\n",
            "preprocess: [37 37 37] ==> [-56.594  -67.7624 -92.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.8995628356933594, 0.4546666741371155]\n",
            "[times]: 75\n",
            "preprocess: [32 36 47] ==> [-46.594  -68.7624 -97.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.8971359729766846, 0.4552631676197052]\n",
            "[times]: 76\n",
            "preprocess: [139 133  99] ==> [ 5.406  28.2376  9.8137]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.8949449062347412, 0.4545454680919647]\n",
            "[times]: 77\n",
            "preprocess: [118 105  96] ==> [  2.406    0.2376 -11.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.8998639583587646, 0.45512819290161133]\n",
            "[times]: 78\n",
            "preprocess: [76 47 15] ==> [-78.594  -57.7624 -53.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.892647385597229, 0.4569620192050934]\n",
            "[times]: 79\n",
            "preprocess: [219 219 219] ==> [125.406  114.2376  89.8137]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.8831738233566284, 0.45750001072883606]\n",
            "[times]: 80\n",
            "preprocess: [61 51 42] ==> [-51.594  -53.7624 -68.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.873430609703064, 0.4592592716217041]\n",
            "[times]: 81\n",
            "preprocess: [50 44 44] ==> [-49.594  -60.7624 -79.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.871650218963623, 0.45975610613822937]\n",
            "[times]: 82\n",
            "preprocess: [129 115 104] ==> [10.406  10.2376 -0.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.8754714727401733, 0.45783132314682007]\n",
            "[times]: 83\n",
            "preprocess: [77 44 13] ==> [-80.594  -60.7624 -52.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.8710253238677979, 0.45773810148239136]\n",
            "[times]: 84\n",
            "preprocess: [134 140 159] ==> [65.406  35.2376  4.8137]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.8725110292434692, 0.4588235318660736]\n",
            "[times]: 85\n",
            "preprocess: [99 99 99] ==> [  5.406   -5.7624 -30.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.8617079257965088, 0.4598837196826935]\n",
            "[times]: 86\n",
            "preprocess: [156 156 156] ==> [62.406  51.2376 26.8137]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.8611822128295898, 0.4597701132297516]\n",
            "[times]: 87\n",
            "preprocess: [65 42 24] ==> [-69.594  -62.7624 -64.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.855139136314392, 0.46022728085517883]\n",
            "[times]: 88\n",
            "preprocess: [39 38 34] ==> [-59.594  -66.7624 -90.1863]\n",
            "(20, 224, 224, 3) (20, 11)\n",
            "[Train]: [1.8435349464416504, 0.4617977440357208]\n",
            "[times]: 89\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXsF6L2e-vzG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_folder_path = 'drive/My Drive/Tibame_AIoT_Project/face'\n",
        "age_model.save_weights(os.path.join(model_folder_path,'keras_vggface_weights_age_256.h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fj8kZIkA3C9o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3aed2565-ffe0-4603-d7fb-58d9bb78c42c"
      },
      "source": [
        "# evaluate\n",
        "_, x_batch, y_batch = get_data(x_test, y_test, IMG_SIZE=224)\n",
        "age_model.evaluate(x_batch, y_batch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5501 - accuracy: 0.3000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.5501019954681396, 0.30000001192092896]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veqfvA2J2UB3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def euclidean_distance(x, y):\n",
        "    sum_square = np.sum(np.square(x - y), keepdims=True)\n",
        "    return np.sqrt(sum_square)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ic1ekdt2Xli",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_age(img):\n",
        "    img_size = 100\n",
        "    img = normalize(img)\n",
        "    img = cv2.resize(img, (img_size, img_size))\n",
        "    model_input = np.zeros((1, img_size, img_size, 3))\n",
        "    model_input[0] = img\n",
        "    ages = age_model.predict(model_input)\n",
        "    print('age: ', ages.argmax(axis=-1))\n",
        "    return \n",
        "\n",
        "# def predict_gender(img):\n",
        "#     img_size = 100\n",
        "#     img = normalize(img)\n",
        "#     img = cv2.resize(img, (img_size, img_size))\n",
        "#     model_input = np.zeros((1, img_size, img_size, 3))\n",
        "#     model_input[0] = img\n",
        "#     genders = model_gender.predict(model_input)\n",
        "#     gender = genders[0]\n",
        "#     if gender > 0.5:\n",
        "#         print('Male')\n",
        "#     else:\n",
        "#         print('Female')\n",
        "#     return    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huWs2jy-2jT8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def face_id(filename, IMG_SIZE=160):\n",
        "    raw_img = cv2.imread(os.path.join(folder_path, filename))[:,:,::-1]\n",
        "    faces = detect_faces(raw_img)\n",
        "    if len(faces) == 0:\n",
        "        print('No face')\n",
        "        return\n",
        "    else:\n",
        "        # get face embeddings\n",
        "        face = faces[0]\n",
        "        # More predictions\n",
        "        predict_age(face)\n",
        "        # predict_emotion(face)\n",
        "        # predict_gender(face)\n",
        "        # # ID\n",
        "        # face = cv2.resize(face, (IMG_SIZE, IMG_SIZE))\n",
        "        # model_input = np.zeros((1, IMG_SIZE, IMG_SIZE, 3))\n",
        "        # model_input[0] = face\n",
        "        # model_input = preprocess(model_input)\n",
        "        # query_embeddings = feature_extractor.predict(model_input)\n",
        "        # query_embedding = query_embeddings[0]\n",
        "        \n",
        "        # # compute distance\n",
        "        # distances = np.zeros((len(embeddings)))\n",
        "        # for i, embed in enumerate(embeddings):\n",
        "        #     distance = euclidean_distance(embed, query_embedding)\n",
        "        #     distances[i] = distance\n",
        "\n",
        "        # # find min distance    \n",
        "        # idx_min = np.argmin(distances)\n",
        "        # distance, name = distances[idx_min], names[idx_min]\n",
        "        # print('name: ', name, ' distance: ',distance)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGRrHjOu2tPf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "folder_path = '/content/drive/My Drive/week10/face_detection'\n",
        "path = 'face3.jpg'\n",
        "face_id(path)\n",
        "plt.imshow(cv2.imread(os.path.join(folder_path, path))[:,:,::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmkvTAM3F2m9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}